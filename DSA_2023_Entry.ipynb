{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"DSA_2023_Entry.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1DroRwx3ENZ"
   },
   "source": [
    "## DSA 2023 Summer School Admittance Check\n",
    "\n",
    "Thanks for your interest in attending DSA Kigali 2023. To attend the summer school you have to have some level of basic Python proficiency. Completing the following notebook should ensure you have the right kind of background to benefit maximally from the Summer School. See you in Kigali!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7Upwjh9U3ENa"
   },
   "outputs": [],
   "source": [
    "# Run these once ... Just in case \n",
    "# !pip install nose \n",
    "# !pip install otter-grader\n",
    "import IPython\n",
    "from IPython import get_ipython\n",
    "# Import the good stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nose.tools import assert_equal\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ibmmx8r3ENc"
   },
   "source": [
    "**Question 1:** Write a Python function to return a tuple of primes and non primes given an integer input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CWjGPqaO3ENc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following are the prime and non prime numbers smaller than or equal to 30\n",
      "((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n"
     ]
    }
   ],
   "source": [
    "def is_prime(num):\n",
    "    '''\n",
    "    Accepts a number as a parameter and returns true if that number is a prime number and false otherwise.\n",
    "    A prime number is defined as a number which is only divisible by one and itself.\n",
    "    '''\n",
    "    for i in range(2, num):\n",
    "        if num % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def sieve(num):\n",
    "    primes = []\n",
    "    non_primes = []\n",
    "\n",
    "    for i in range(2, num + 1):\n",
    "        if is_prime(i):\n",
    "            primes.append(i)\n",
    "        else:\n",
    "            non_primes.append(i)\n",
    "            \n",
    "    nums = (tuple(primes), tuple(non_primes))\n",
    "    return nums\n",
    "\n",
    "num = 30\n",
    "print(\"Following are the prime and non prime numbers smaller than or equal to\", num)\n",
    "print(sieve(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntYqVxEQ3ENd"
   },
   "source": [
    "**Question 2:** Create a dictionary to store the type and number of unique characters in the paragraph provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LlZ8GC4J3ENe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T': 3, 'h': 17, 'e': 89, ' ': 192, 'f': 26, 'o': 68, 'l': 35, 'w': 16, 'i': 60, 'n': 42, 'g': 14, 's': 57, 'a': 48, 'm': 20, 'p': 11, 't': 65, 'x': 3, 'I': 1, 'u': 26, 'd': 27, 'r': 45, 'c': 31, 'k': 9, 'y': 19, 'b': 11, '.': 12, ':': 2, '1': 11, '2': 10, '3': 13, '4': 5, '5': 3, '6': 3, '7': 10, '8': 3, '9': 2, 'S': 2, 'V': 1, '‚Äô': 3, '0': 22, ',': 7, '(': 3, ')': 3, 'q': 3, 'A': 2, 'v': 4, 'F': 1, '-': 4, '{': 2, '}': 2, 'O': 3, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '`': 2, '*': 4, '^': 4, '‚Äú': 1, '‚Äù': 1, '‚Äò': 1, 'E': 1, '/': 1, '\\\\': 1}\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"The following is sample text I used to practice special characters using keybr.com: 112233445566778899 Saturn V rocket‚Äôs first stage carries 203,400 gallons (770,000 liters) of kerosene fuel and 318,000 gallons (1.2 million liters) of liquid oxygen needed for combustion. At liftoff, the stage‚Äôs five F-1 rocket engines ignite and produce 7.5 million pounds of thrust. To replace those goofy quantities with the far less retarded metric system (even though liters are considered part of the metric system they are the same as cubic deci-meters) you would say 770 cubic meters of kerosene {abbreviated as m3} and 1,204 m3 of liquid O2 [O2 is the symbol for oxygen]. We would also say it produced 33,600,000 newtons of force <abbreviated as N>. To add scientific notation {a way of writing numbers that allows you to write only as many digits `of specificity` as you would like} you can write 7.7 * 10 ^ 2 m3 of kerosene 1.204 * 10 ^ 3 m3 of O2 and 3.3 * 10 ^ 7 newtons. Another way to write scientific notation is to replace the ‚Äú* 10 ^‚Äù with ‚ÄòE‚Äô -/capital e\\-. So our numbers would look like:s\"\n",
    "\n",
    "dictionary = {}\n",
    "for word in paragraph:\n",
    "    if word in dictionary:\n",
    "        dictionary[word] = dictionary[word] + 1\n",
    "    else:\n",
    "        dictionary[word] = 1\n",
    "\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylvPVW8m3ENe"
   },
   "source": [
    "**Question 3:** Extract the values from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "I50ccd1SJMn4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "keysList = dictionary.values()\n",
    "print (keysList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hucvAvprJMn5"
   },
   "source": [
    "**Question 4:** Extract the keys from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wLHoBNERJMn5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\'])\n"
     ]
    }
   ],
   "source": [
    "valuesList = dictionary.keys()\n",
    "print (valuesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PpnMsGpJMn5"
   },
   "source": [
    "**Question 5:** Merge the two lists into a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UDWWh3vQJMn5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n"
     ]
    }
   ],
   "source": [
    "final_tuple = (tuple(valuesList), tuple(keysList))\n",
    "print(final_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:**  Write a function `greatest_common_divisor` that takes two inputs `a` and `b` and returns the greatest common divisor of the two numbers. E.g. input `(10, 15)` would return `5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greatest_common_divisor(a, b):\n",
    "    smaller_num = min(a, b)\n",
    "    gcd = 1\n",
    "\n",
    "    for i in range(2, smaller_num):\n",
    "        if a % i == 0 and b % i == 0:\n",
    "            gcd = i\n",
    "    \n",
    "    return gcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q6 results: All test cases passed!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:**  Write a function `get_nearest_farthest` that takes in a point of interest (pt) and a list of points and returns the nearest point and the farthest point from the point of intest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distance_between_points(a, b):\n",
    "    '''\n",
    "    Accepts two points in 2D space, a & b and uses the Euclidean distance formula to calculate the distance between them.\n",
    "    '''\n",
    "    return math.sqrt((b[0] - a[0])**2 + (b[1] - a[1])**2)\n",
    "\n",
    "def get_nearest_farthest(pt, ptlist):\n",
    "    max_distance = float('-inf')\n",
    "    min_distance = float('inf')\n",
    "    closest_point = ()\n",
    "    furthest_point = ()\n",
    "    \n",
    "    for i in ptlist:\n",
    "        curr_distance = distance_between_points(pt, i)\n",
    "        \n",
    "        if curr_distance > max_distance:\n",
    "            max_distance = curr_distance\n",
    "            furthest_point = i\n",
    "        if curr_distance < min_distance:\n",
    "            min_distance = curr_distance\n",
    "            closest_point = i\n",
    "    \n",
    "    return (closest_point, furthest_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed! üôå</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:**  Write a function `perfectly_divisible` to return a list of numbers between 0 and a number $N$ that are perfectly divisible by $q$ (with out leaving a remainder). <br>\n",
    "**Hint**: $N$ should also be inclusive in the numbers being considered. If N is negative use N == 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perfectly_divisible(N, q):\n",
    "    if N < 0:\n",
    "        N = 20\n",
    "    \n",
    "    divisible_nums = []\n",
    "    for i in range(N + 1):\n",
    "        if i % q == 0:\n",
    "            divisible_nums.append(i)\n",
    "\n",
    "    return divisible_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8</pre></strong> passed! üíØ</p>"
      ],
      "text/plain": [
       "q8 results: All test cases passed!"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:**  Write a function `flatten_lists` that takes in a list of lists and outputs a sorted list of elements of sublists of the input list (confusing right?) <br>\n",
    "Example: given `flatten_lists([[2,13,44], [6,7]])` it should return `[2,6,7,13,44]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_lists(superlist):\n",
    "    flattened_list = []\n",
    "\n",
    "    for sublist in superlist:\n",
    "        for i in sublist:\n",
    "            flattened_list.append(i)\n",
    "\n",
    "    return sorted(flattened_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q9</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q9 results: All test cases passed!"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Extra Mile!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_egf664jJMn5"
   },
   "source": [
    "**Download the dataset \"Nakuru Sensor Data for February 2023 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/14165682-37dd-4f40-914e-eb24619e4ef8\"**\n",
    "\n",
    "Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "r2lE0yrPJMn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp     object\n",
      "value_type    object\n",
      "value          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "#Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe \n",
    "\n",
    "df = pd.read_csv(r'Nakuru_Sensor_Data_Feb_2023.csv',usecols=['timestamp','value_type','value'], sep=';')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er6lemMeJMn5"
   },
   "source": [
    "**Question E1:** Create a new collumn 'timestamp_new' from 'timestamp' rounded off to the second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "sQq3JIaVJMn5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              timestamp   value_type  value   \n",
      "0      2023-02-04T04:22:51.323124+00:00     humidity    100  \\\n",
      "1      2023-02-04T04:22:51.323124+00:00  temperature     12   \n",
      "2      2023-02-04T04:22:51.323125+00:00           P2     27   \n",
      "3      2023-02-04T04:22:51.323125+00:00           P1     59   \n",
      "4      2023-02-04T04:25:32.354784+00:00     humidity    100   \n",
      "...                                 ...          ...    ...   \n",
      "42985  2023-02-24T07:51:55.687329+00:00  temperature     27   \n",
      "42986  2023-02-24T07:54:35.530536+00:00     humidity     59   \n",
      "42987  2023-02-24T07:54:35.530536+00:00  temperature     27   \n",
      "42988  2023-02-24T07:54:35.530545+00:00           P2      0   \n",
      "42989  2023-02-24T07:54:35.530545+00:00           P1      0   \n",
      "\n",
      "                  timestamp_new  \n",
      "0     2023-02-04 04:22:51+00:00  \n",
      "1     2023-02-04 04:22:51+00:00  \n",
      "2     2023-02-04 04:22:51+00:00  \n",
      "3     2023-02-04 04:22:51+00:00  \n",
      "4     2023-02-04 04:25:32+00:00  \n",
      "...                         ...  \n",
      "42985 2023-02-24 07:51:56+00:00  \n",
      "42986 2023-02-24 07:54:36+00:00  \n",
      "42987 2023-02-24 07:54:36+00:00  \n",
      "42988 2023-02-24 07:54:36+00:00  \n",
      "42989 2023-02-24 07:54:36+00:00  \n",
      "\n",
      "[42990 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df['timestamp_new']=pd.to_datetime(df['timestamp']).dt.round('S') # seconds\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HM8DysCJMn6"
   },
   "source": [
    "**Question E2:** Split the dataframe based on the 'value_type' collumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "z3NUYMOZJMn6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(by='value_type').apply(lambda x: x)\n",
    "df_temperature = df[df['value_type']=='temperature']\n",
    "df_temperature.to_csv(r'Temperature.csv')\n",
    "df_humidity = df[df['value_type']=='humidity']\n",
    "df_humidity.to_csv(r'humidity.csv')\n",
    "df_P1 = df[df['value_type']=='P1']\n",
    "df_P1.to_csv(r'P1.csv')\n",
    "df_P2 = df[df['value_type']=='P2']\n",
    "df_P2.to_csv(r'P2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAEsAuUvJMn6"
   },
   "source": [
    "**Question E3:** Find the mean, mode and median of the humidity, temperature, P1 and P2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "14T6jzZ_JMn6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature\n",
      "Mean =  22.35287548855388 Median =  22.0 Standard Deviation =  7.218686624924896\n",
      "Humidity\n",
      "Mean =  64.31109249953471 Median =  61.0 Standard Deviation =  22.407697062564353\n",
      "P1\n",
      "Mean =  28.508605451669922 Median =  20.0 Standard Deviation =  33.691468361874755\n",
      "P2\n",
      "Mean =  11.30142338822216 Median =  8.0 Standard Deviation =  11.865466667566395\n"
     ]
    }
   ],
   "source": [
    "mu_temp=df_temperature[\"value\"].mean()\n",
    "med_temp = df_temperature[\"value\"].median()\n",
    "sd_temp = df_temperature[\"value\"].std()\n",
    "print(\"Temperature\")\n",
    "print(\"Mean = \",mu_temp, \"Median = \", med_temp, \"Standard Deviation = \", sd_temp)\n",
    "\n",
    "mu_humidity=df_humidity[\"value\"].mean()\n",
    "med_humidity = df_humidity[\"value\"].median()\n",
    "sd_humidity = df_humidity[\"value\"].std()\n",
    "print(\"Humidity\")\n",
    "print(\"Mean = \",mu_humidity, \"Median = \", med_humidity, \"Standard Deviation = \", sd_humidity)\n",
    "\n",
    "mu_P1=df_P1[\"value\"].mean()\n",
    "med_P1 = df_P1[\"value\"].median()\n",
    "sd_P1 = df_P1[\"value\"].std()\n",
    "print(\"P1\")\n",
    "print(\"Mean = \",mu_P1, \"Median = \", med_P1, \"Standard Deviation = \", sd_P1)\n",
    "\n",
    "mu_P2=df_P2[\"value\"].mean()\n",
    "med_P2 = df_P2[\"value\"].median()\n",
    "sd_P2 = df_P2[\"value\"].std()\n",
    "print(\"P2\")\n",
    "print(\"Mean = \",mu_P2, \"Median = \", med_P2, \"Standard Deviation = \", sd_P2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKWBykh-JMn6"
   },
   "source": [
    "**Question E4:** Merge the grouped dataframes into one dataframe and save it as newdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "4mQSIPfhJMn6",
    "tags": []
   },
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'value_x', 'value_type_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df_merged\u001b[39m=\u001b[39mdf_temperature\u001b[39m.\u001b[39mmerge(df_humidity, on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtimestamp_new\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m df_merged\u001b[39m=\u001b[39mdf_merged\u001b[39m.\u001b[39mmerge(df_P1, on\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtimestamp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtimestamp_new\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m df_merged\u001b[39m=\u001b[39mdf_merged\u001b[39m.\u001b[39;49mmerge(df_P2, on\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtimestamp_new\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(df_merged)\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path  \n",
      "File \u001b[0;32m~/Documents/Programs/Python/DSA/.venv/lib/python3.9/site-packages/pandas/core/frame.py:9843\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9824\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   9825\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   9826\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9839\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9840\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9841\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[0;32m-> 9843\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m   9844\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   9845\u001b[0m         right,\n\u001b[1;32m   9846\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9847\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9848\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m   9849\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m   9850\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m   9851\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m   9852\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9853\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m   9854\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   9855\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m   9856\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   9857\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Programs/Python/DSA/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:156\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    126\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    142\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    143\u001b[0m         left,\n\u001b[1;32m    144\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/Documents/Programs/Python/DSA/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:805\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m    803\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 805\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[1;32m    806\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[1;32m    807\u001b[0m )\n\u001b[1;32m    808\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[1;32m    810\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/Documents/Programs/Python/DSA/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:757\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    754\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[1;32m    755\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[0;32m--> 757\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    758\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    761\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[39mlen\u001b[39m(left)):\n\u001b[1;32m    762\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    766\u001b[0m         join_index,\n\u001b[1;32m    767\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    772\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    773\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Programs/Python/DSA/.venv/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2590\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2588\u001b[0m     dups\u001b[39m.\u001b[39mextend(rlabels[(rlabels\u001b[39m.\u001b[39mduplicated()) \u001b[39m&\u001b[39m (\u001b[39m~\u001b[39mright\u001b[39m.\u001b[39mduplicated())]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m   2589\u001b[0m \u001b[39mif\u001b[39;00m dups:\n\u001b[0;32m-> 2590\u001b[0m     \u001b[39mraise\u001b[39;00m MergeError(\n\u001b[1;32m   2591\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing \u001b[39m\u001b[39m'\u001b[39m\u001b[39msuffixes\u001b[39m\u001b[39m'\u001b[39m\u001b[39m which cause duplicate columns \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mset\u001b[39m(dups)\u001b[39m}\u001b[39;00m\u001b[39m is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2592\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnot allowed.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2593\u001b[0m     )\n\u001b[1;32m   2595\u001b[0m \u001b[39mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[0;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'value_x', 'value_type_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "# df_merged=pd.merge(pd.merge(pd.merge(df_temperature, df_humidity, on=['timestamp', 'timestamp_new']), df_P1, on='timestamp'), df_P2, on='timestamp')\n",
    "df_merged=df_temperature.merge(df_humidity, on=['timestamp', 'timestamp_new'])\n",
    "df_merged=df_merged.merge(df_P1, on=['timestamp', 'timestamp_new'])\n",
    "df_merged=df_merged.merge(df_P2, on=['timestamp', 'timestamp_new'])\n",
    "# df_merged=grouped.melt()\n",
    "print(df_merged)\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged.to_csv(filepath)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNLVvAvbJMn6"
   },
   "source": [
    "**Question E5:** Open the new data file and select only 'timestamp_new','value_temperature','value_humidity','value_P1' and 'value_P2' collunms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4fyxaLq2JMn6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "new_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh5va_ODJMn6"
   },
   "source": [
    "**Question E6:** Replace the missing values in collumns 'value_P1' and 'value_P2' with the mean of the same collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAm29MW0JMn7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check for missing values \n",
    "missing_values = ...\n",
    "\n",
    "# displaying data only with NaN\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJ2zFruYJMn7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(\"The mean of P1\",new_df['value_P2'].mean())\n",
    "#print(\"The mean of P2\",new_df['value_P1'].mean())\n",
    "\n",
    "#replace missing values with the mean \n",
    "...\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syjHmz-AJMn7"
   },
   "source": [
    "**Question E7:** Compute the correlations between temperature and humidity; P1 and P2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agvSVKsEJMn7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Correlation between temperature and humidity\n",
    "...\n",
    "\n",
    "print (\"Correlation between temparature and humidity\",corr_temp_hum)\n",
    "\n",
    "#Correlation between P1 and P2\n",
    "...\n",
    "\n",
    "print (\"Correlation between P1 and P2\",corr_p1_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIy00VyKJMn7"
   },
   "source": [
    "**Question E8:** Create a new dataframe comprising of the average values of the variables by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qb_G74GPJMn7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "means_feb = ...\n",
    "means_feb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXrFVTUPJMn7"
   },
   "source": [
    "**Question E9:** Download the dataset \"Nakuru Sensor Data for November 2021 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/1f11351e-156b-4e4c-a063-b86a6ee07c4a\"\n",
    "\n",
    "Load the data into a pandas dataframe and develop a dataframe similar to what you have just done in Question no's 6 - 13 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooqx8xuoJMn7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "means_nov = ...\n",
    "means_nov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7RRkZpnYqa"
   },
   "source": [
    "**Question E10:** Convert the means_feb and means_nov to numpy arrays ... and then compute the average of each collumn\n",
    "\n",
    "Hint: The results are numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbgK6RQ8nDXw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "feb_numpy_array = ...\n",
    "feb_average = ...\n",
    "feb_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6-iwnWSoIDE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "nov_numpy_array = ...\n",
    "nov_average = ...\n",
    "nov_average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc6tiksMqSb0"
   },
   "source": [
    "**Question E11:** Write a function to compute the difference in the average temperature, humidity, P1 and P2 between November 2021 and February 2023\n",
    "\n",
    "Hint: The result is a vector of the form [w,x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWCrhXpKqPJQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sub():\n",
    "    ...\n",
    "    return diff\n",
    " \n",
    "# Print the result of the subtraction\n",
    "difference = sub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload the generated zip file to the Google sheet please. Uploading work which is not yours will lead to non admittance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_primes(sieve):\n...     assert sieve(30) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n>>> test_primes(sieve)  \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_dictionary(Counter):\n...     assert Counter(paragraph) == {' ': 192, 'e': 89, 'o': 68, 't': 65, 'i': 60, 's': 57, 'a': 48, 'r': 45, 'n': 42, 'l': 35, 'c': 31, 'd': 27, 'f': 26, 'u': 26, '0': 22, 'm': 20, 'y': 19, 'h': 17, 'w': 16, 'g': 14, '3': 13, '.': 12, 'p': 11, 'b': 11, '1': 11, '2': 10, '7': 10, 'k': 9, ',': 7, '4': 5, 'v': 4, '-': 4, '*': 4, '^': 4, 'T': 3, 'x': 3, '5': 3, '6': 3, '8': 3, '‚Äô': 3, '(': 3, ')': 3, 'q': 3, 'O': 3, ':': 2, '9': 2, 'S': 2, 'A': 2, '{': 2, '}': 2, '`': 2, 'I': 1, 'V': 1, 'F': 1, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '‚Äú': 1, '‚Äù': 1, '‚Äò': 1, 'E': 1, '/': 1, '\\\\': 1}\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_keyslist():\n...     assert list(dictionary.keys()) == ['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\']\n>>> test_keyslist() \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_valueslist():\n...     assert list(dictionary.values()) == [3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_tuple():\n...     assert final_tuple == (('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n>>> test_tuple() \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(greatest_common_divisor(10, 15), 5)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(get_nearest_farthest((3, 8), [(9, 3), (8,5), (7,6)]), ((7, 6), (9, 3)))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(perfectly_divisible(10,2), [0,2,4,6,8,10])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(flatten_lists([[2,13,44], [6,7]]), [2, 6, 7, 13, 44])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
